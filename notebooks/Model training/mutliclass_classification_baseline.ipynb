{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# %cd /content/drive/MyDrive/Sun/ML Shock/Final project/\n","import sys\n","sys.path.insert(0,\"C:/Users/Amy/Desktop/Green_Git/eegClassification/utils\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from torch.utils.data import DataLoader\n","import pandas as pd\n","import os\n","import numpy as np\n","\n","# import CustomDataset from CustomDataset.py from utils folder\n","from CustomDataset import CustomDataset\n","\n","from scipy.special import kl_div"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load (train or test) data from csv file\n","path = \"C:/Users/Amy/Desktop/Green_Git/eegClassification/sample_data/\"\n","# path = \"./data/\"\n","\n","data_type = \"spec\" # \"eeg_raw\" #\"eeg_spec\"  #\n","train = True\n","text = \"train\" if train else \"test\"\n","\n","scaler_path = \"C:/Users/Amy/Desktop/Green_Git/eegClassification/models/scalers/\"\n","scaler_type = \"min_max\" #\"standard\" # \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","data_dir = (\n","    f\"{text}_eegs/\"\n","    if \"eeg\" in data_type\n","    else f\"{text}_spectrograms/\"\n",")\n","data_dir = path + data_dir\n","\n","df = pd.read_csv(path + f\"{text}.csv\")\n","\n","votes_cols = [\n","    \"seizure_vote\",\n","    \"lpd_vote\",\n","    \"gpd_vote\",\n","    \"lrda_vote\",\n","    \"grda_vote\",\n","    \"other_vote\",\n","]\n","label_cols = (\n","    [\"eeg_id\", \"label_id\", \"eeg_label_offset_seconds\"]\n","    if \"eeg\" in data_type\n","    else [\"spectrogram_id\", \"label_id\", \"spectrogram_label_offset_seconds\"]\n",")\n","offset = (\n","    [\"eeg_label_offset_seconds\"]\n","    if \"eeg\" in data_type\n","    else [\"spectrogram_label_offset_seconds\"]\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["files = os.listdir(data_dir)\n","df = df[\n","    df[\"eeg_id\" if \"eeg\" in data_type else \"spectrogram_id\"].isin(\n","        [int(f.split(\".\")[0]) for f in files]\n","    )\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# if info_cols not in df add it and set to zero\n","for col in offset:\n","    if col not in df.columns:\n","        df[col] = 0\n","# if df does not contain \"label_id\" add a unique label_id\n","if \"label_id\" not in df.columns:\n","    df[\"label_id\"] = range(len(df))\n","\n","info = {}\n","df_gr = df.groupby(label_cols)\n","for name, group in df_gr:\n","    # first row of group\n","    info[name] = {\"votes\": group[votes_cols].values[0] if train else None}\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# load scaler from path +f'{data_type}_standard_scaler.pkl' from pickle file\n","import pickle\n","\n","with open(scaler_path + f\"{data_type}_{scaler_type}_scaler.pkl\", \"rb\") as f:\n","    scaler = pickle.load(f)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset = CustomDataset(data_dir, data_type, info, transform=(lambda x: scaler.transform(x),))\n","dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"]},{"cell_type":"code","execution_count":72,"metadata":{"id":"T1TSt9Y-ePSQ"},"outputs":[],"source":["def get_error(y_true, y_pred):\n","    return np.mean(kl_div(y_true, y_pred))\n","\n","\n","def evaluate(dataloader, y_pred):\n","    error = []\n","    count = 0\n","    for _, _, y in dataloader:\n","        for i in range(y.shape[0]):\n","            error.append(get_error(y[i].numpy(), y_pred[count]))\n","            count += 1\n","    return np.mean(error)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":73,"metadata":{"id":"WMUJcX_YePSQ"},"outputs":[{"name":"stdout","output_type":"stream","text":["error for uniform predictio: 0.19\n"]}],"source":["error = []\n","count = 0\n","dummy = [1/6 for _ in range(6)]\n","for _, _, y in dataloader:\n","    for i in range(y.shape[0]):\n","        error.append(get_error(y[i].numpy(), dummy))\n","        count += 1\n","\n","print(f'error for uniform predictio: {sum(error)/count:.2f}')"]},{"cell_type":"markdown","metadata":{"id":"epeebrbvePSR"},"source":["## Gradient boost classifier"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["# # load the pca\n","# with open(path + f'{data_type}_pca.pkl', 'rb') as f:\n","#     pca = pickle.load(f)"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[],"source":["# load the data\n","training_data = CustomDataset(data_dir, data_type = data_type)#, \n","                            #   transform = (lambda x: standard_scaler.transform(x), lambda x: pca.transform(x.reshape(1,-1))))\n","train_dataloader = DataLoader(training_data, batch_size=16, shuffle=True)"]},{"cell_type":"code","execution_count":75,"metadata":{"id":"xGN8UzCWePSS"},"outputs":[],"source":["# train a gradient boosting model to predict one of the 6 classes\n","from sklearn.ensemble import GradientBoostingClassifier\n","\n","model = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n","for X, y, _ in train_dataloader:\n","    model.fit(X.reshape(X.shape[0], -1), y)\n","\n"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([14, 6]) (14, 2)\n"]},{"ename":"ValueError","evalue":"operands could not be broadcast together with shapes (6,) (2,) ","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[56], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape, y_pred\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m----> 8\u001b[0m         error \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mget_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m         count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror for the model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;241m/\u001b[39mcount\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n","Cell \u001b[1;32mIn[12], line 4\u001b[0m, in \u001b[0;36mget_error\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_error\u001b[39m(y_true, y_pred):\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(\u001b[43mkl_div\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m)\n","\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (6,) (2,) "]}],"source":["# compute the error on the training set\n","error = 0 \n","count = 0\n","for X, _, y in train_dataloader:\n","    y_pred = model.predict_proba(X.reshape(X.shape[0], -1))\n","    print(y.shape, y_pred.shape)\n","    for i in range(y.shape[0]):\n","        error += get_error(y[i].numpy(), y_pred[i])\n","        count += 1\n","\n","print(f'error for the model: {error/count:.2f}')"]},{"cell_type":"code","execution_count":48,"metadata":{"id":"cWx5EpJcePSX"},"outputs":[],"source":["# # predict the class probabilities\n","# y_train_pred = model.predict_proba(X_train_pca)\n","# y_valid_pred = model.predict_proba(X_valid_pca)\n","# y_test_pred = model.predict_proba(X_test_pca)\n","\n","# # calculate the error\n","# error_train = [get_error(y_true, y_pred) for y_true, y_pred in zip(y_train, y_train_pred)]\n","# error_valid = [get_error(y_true, y_pred) for y_true, y_pred in zip(y_valid, y_valid_pred)]\n","# error_test = [get_error(y_true, y_pred) for y_true, y_pred in zip(y_test, y_test_pred)]\n","\n","# print(f'train error: {np.mean(error_train):.2f}')\n","# print(f'valid error: {np.mean(error_valid):.2f}')\n","# print(f'test error: {np.mean(error_test):.2f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J_DOVknDePSX"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FoG1llnIePSX"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}
