{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"w_Yya6PM-So0"},"outputs":[],"source":["local = True"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":782104,"status":"ok","timestamp":1713635040248,"user":{"displayName":"Amy Rouillard","userId":"08070373675321350328"},"user_tz":-120},"id":"E-BxHOx62rbf","outputId":"d26ff58a-44b9-4ef4-ed51-d135e550a1ab"},"outputs":[],"source":["if not local:\n","    from google.colab import drive\n","    drive.mount('/content/drive')#, force_remount=True)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":895,"status":"ok","timestamp":1713635041087,"user":{"displayName":"Amy Rouillard","userId":"08070373675321350328"},"user_tz":-120},"id":"RfPr4NSH2rbn","outputId":"f1a6da9c-81f9-4062-9ef4-b24f8cf67ca0"},"outputs":[],"source":["if not local:\n","    %cd /content/drive/MyDrive/Sun/ML Shock/Final project/"]},{"cell_type":"markdown","metadata":{"id":"ud5gHwGZ2rbo"},"source":["# Convolutional Neural Networks\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Ceyg_R2A2rbq"},"outputs":[],"source":["import sys\n","if local:\n","    sys.path.insert(0,\"C:/Users/Amy/Desktop/Green_Git/eegClassification/utils\")\n","else:\n","    sys.path.insert(0,\"/content/drive/MyDrive/Sun/ML Shock/Final project/\")"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"Uqw8yc5U2rbr"},"outputs":[],"source":["# Import libraries\n","import torch\n","import numpy as np\n","from tqdm import tqdm\n","\n","from CustomDataLoaderNPY import CustomDataset\n","from torch.utils.data import DataLoader\n","from model_architectures import CustomCNN, TransNet_Resnet18, TransNet_Efficientnetb0\n","\n","import os"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":67,"status":"ok","timestamp":1713635050041,"user":{"displayName":"Amy Rouillard","userId":"08070373675321350328"},"user_tz":-120},"id":"uGiNfN2Y2rbs","outputId":"76fd9821-23aa-4612-cd64-44185f8f7157"},"outputs":[{"name":"stdout","output_type":"stream","text":["CUDA is not available.  Training on CPU ...\n"]}],"source":["# check if CUDA is available\n","train_on_gpu = torch.cuda.is_available()\n","\n","if not train_on_gpu:\n","    print('CUDA is not available.  Training on CPU ...')\n","else:\n","    print('CUDA is available!  Training on GPU ...')\n","    print(\"GPU count\", torch.cuda.device_count())"]},{"cell_type":"markdown","metadata":{"id":"05PrQ0pR2rbu"},"source":["---\n","## Load the Data"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"vYU0CgCI2rbv"},"outputs":[],"source":["# Load (train or test) data from csv file\n","if local:\n","    path = \"C:/Users/Amy/Desktop/Green_Git/eegClassification/data/\"\n","    path_df = \"C:/Users/Amy/Desktop/Green_Git/eegClassification/files/\"\n","else:\n","    path = \"./data_prep_all_spec/\"\n","    path_df = \"./data/\"\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"nLS4zDMr2rbv"},"outputs":[],"source":["# Type of input data\n","data_type = \"eeg_spec\"  #\"spec\" # \"eeg_raw\" #\n","# number of subprocesses to use for data loading\n","import multiprocessing as cpu\n","num_workers = 0 #cpu.cpu_count() #- 1\n","# how many samples per batch to load\n","batch_size = 64\n","# label smoothing\n","label_smoothing = 0.01"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"WPHFZfTG2rbw"},"outputs":[],"source":["if data_type == \"spec\":\n","    input_shape = (3,400,299)\n","elif data_type == \"eeg_spec\":\n","    input_shape = (20,129,43)\n","elif data_type == \"eeg_raw\":\n","    input_shape = (20,9800)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8241,"status":"ok","timestamp":1713635058217,"user":{"displayName":"Amy Rouillard","userId":"08070373675321350328"},"user_tz":-120},"id":"QGxud2TG_bT-","outputId":"79973af1-7ca1-439c-fd4d-f62d5a2018b7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of items 700\n"]}],"source":["data_path = path+f'data_prep_all_{data_type}/train/'\n","data_files = os.listdir(data_path)\n","data_files = [f.split('.')[0].split('_')[1] for f in data_files if f.startswith('images')]\n","N_items = len(data_files)\n","text = 'features'\n","\n","print(\"Number of items\", N_items)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"7osZJv8X2rby"},"outputs":[],"source":["# specify the image classes\n","classes = [\n","        \"seizure_vote\",\n","        \"lpd_vote\",\n","        \"gpd_vote\",\n","        \"lrda_vote\",\n","        \"grda_vote\",\n","        \"other_vote\",\n","    ]\n","N_classes = len(classes)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"QxiuprlZRCIO"},"outputs":[],"source":["get_batch_transform = lambda x, y: (\n","    x[0, :],\n","    y[0, :],\n",")"]},{"cell_type":"markdown","metadata":{"id":"9SlF-9PT2rb0"},"source":["\n","## Define the Network Architecture\n"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":85,"status":"ok","timestamp":1713635058218,"user":{"displayName":"Amy Rouillard","userId":"08070373675321350328"},"user_tz":-120},"id":"s9SG-O8M-SpI","outputId":"06488a6a-6bfd-4124-f799-2e58172f1cb0"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Amy\\Desktop\\Green_Git\\eegClassification\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","c:\\Users\\Amy\\Desktop\\Green_Git\\eegClassification\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\Amy/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:15<00:00, 2.96MB/s]\n"]}],"source":["model_name = \"TransNet_Resnet18\" #\"CustomCNN\" # \"TransNet_Efficientnetb0\" #\n","\n","\n","if model_name == \"CustomCNN\":\n","  model = CustomCNN(input_shape=input_shape, N_classes = N_classes)\n","elif model_name == \"TransNet_Resnet18\":\n","  model = TransNet_Resnet18(input_shape=input_shape, N_classes = N_classes)\n","elif model_name == \"TransNet_Efficientnetb0\":\n","  model = TransNet_Efficientnetb0(input_shape=input_shape, N_classes = N_classes)\n","else:\n","  raise ValueError(\"Model not found\")\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"NRhB4evygbFi"},"outputs":[],"source":["# index = 0\n","# path_model_old = f\"./model_{model_name}_{index}.pt\"\n","# model.load_state_dict(torch.load(path_model_old))\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":74,"status":"ok","timestamp":1713635058218,"user":{"displayName":"Amy Rouillard","userId":"08070373675321350328"},"user_tz":-120},"id":"4tObC1gm2rb0","outputId":"349f8b3b-0752-467f-90a0-3c2359e3356d"},"outputs":[{"data":{"text/plain":["TransNet_Resnet18(\n","  (model): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","    (fc): Identity()\n","  )\n",")"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"JnlN8cYg2rb0"},"outputs":[],"source":["# move tensors to GPU if CUDA is available\n","if train_on_gpu:\n","    model.cuda()"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":73,"status":"ok","timestamp":1713635058218,"user":{"displayName":"Amy Rouillard","userId":"08070373675321350328"},"user_tz":-120},"id":"CpJqVHgHjBrh","outputId":"4a3d12d4-d18a-45fb-8a20-4b04cb8a1b3c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of parameters in the model 11176512\n","Number of trainable parameters in the model 0\n"]}],"source":["num_parameters = sum(p.numel() for p in model.parameters())\n","print('Number of parameters in the model', num_parameters)\n","\n","# number of trainable parameters\n","num_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","print('Number of trainable parameters in the model', num_parameters)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":426},"executionInfo":{"elapsed":289832,"status":"error","timestamp":1713635347978,"user":{"displayName":"Amy Rouillard","userId":"08070373675321350328"},"user_tz":-120},"id":"D8sIGInBRQP7","outputId":"8065e588-e1cf-4e70-e6d0-b7b11b01fd30"},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/700 [00:00<?, ?it/s]"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 700/700 [44:37<00:00,  3.82s/it]  \n"]}],"source":["path_out = f\"./{model_name}_{text}_{data_type}/\"\n","\n","if not os.path.exists(path_out):\n","    os.makedirs(path_out)\n","\n","\n","loader = DataLoader(CustomDataset(data_path, data_files), batch_size=1, shuffle=False, num_workers=num_workers)\n","\n","count = 0\n","for data, votes in tqdm(loader):\n","\n","    data, votes = get_batch_transform(data, votes)\n","    # votes = votes * (1 - label_smoothing) + label_smoothing / N_classes\n","\n","    if train_on_gpu:\n","        data, votes = data.cuda(), votes.cuda()\n","\n","    output = model(data)\n","\n","    # save output as npy\n","    output = output.cpu().detach().numpy()\n","    np.save(path_out + f\"{text}_{count}.npy\", output)\n","\n","    votes = votes.cpu().detach().numpy()\n","    np.save(path_out + f\"votes_{count}.npy\", votes)\n","\n","    count += 1"]},{"cell_type":"markdown","metadata":{},"source":["# Reload inferred data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["text = 'features'\n","data_path = path+f'data/{model_name}_{text}_{data_type}/'\n","data_files = os.listdir(data_path)\n","data_features = [f for f in data_files if f.startswith(text)]\n","data_votes = [f for f in data_files if f.startswith('votes')]\n","N_items = len(data_features)\n","\n","print(\"Number of items\", N_items)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","np.load(data_path+data_features[0]).shape, np.load(data_path+data_votes[0]).shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# load all data_features into a single numpy array\n","X = np.zeros((N_items,*input_shape))\n","for i in range(N_items):\n","    X[i] = np.load(data_path+data_features[i])\n","\n","# load all data_votes into a single numpy array\n","Y = np.zeros((N_items, batch_size, N_classes))\n","for i in range(N_items):\n","    Y[i] = np.load(data_path+data_votes[i])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X.shape, Y.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X = X.reshape(N_items*batch_size, N_classes)\n","Y = Y.reshape(N_items*batch_size, N_classes)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X.shape, Y.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# convert votes to class probabilities\n","Y = Y/np.sum(Y, axis=1)[:,np.newaxis]\n","X = X/np.sum(X, axis=1)[:,np.newaxis]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["predictions = np.argmax(X, axis=1)\n","y_test_class = np.argmax(Y, axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["predictions[0], y_test_class[0]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# evaluate predictions\n","from sklearn.metrics import accuracy_score\n","\n","accuracy = accuracy_score(y_test_class, predictions)\n","print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","confusion_matrix = confusion_matrix(y_test_class, predictions)\n","\n","plt.figure(figsize=(10, 10))\n","sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap='Blues')\n","plt.xticks(ticks=np.arange(6) + 0.5, labels=classes)\n","plt.yticks(ticks=np.arange(6) + 0.5, labels=classes)\n","plt.xlabel('Predicted')\n","plt.ylabel('Actual')\n","plt.title('Confusion Matrix')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# evaluate using kl divergence\n","from scipy.stats import entropy\n","kl_div = np.mean([entropy(Y[i], X[i]) for i in range(len(Y))])\n","lk_base = np.mean([entropy(Y[i], np.array([1/6]*6)) for i in range(len(Y))])\n","print(f\"KL div: {kl_div:.3f} (baseline: {lk_base:.3f})\")"]}],"metadata":{"accelerator":"GPU","anaconda-cloud":{},"colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":0}
