{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3938,"status":"ok","timestamp":1710272418216,"user":{"displayName":"Amy Rouillard","userId":"08070373675321350328"},"user_tz":-120},"id":"3rwOd8GaXPE_","outputId":"bf9b62ce-f577-46e1-b1a2-45e078ec6c64"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1710272446836,"user":{"displayName":"Amy Rouillard","userId":"08070373675321350328"},"user_tz":-120},"id":"jFgK3bDaXPFD","outputId":"76853b11-6ee7-4e54-aac6-18df51187966"},"outputs":[],"source":["# %cd /content/drive/MyDrive/Sun/ML Shock/Final project/\n","import sys\n","sys.path.insert(0,\"C:/Users/Amy/Desktop/Green_Git/eegClassification/utils\")"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":7464,"status":"ok","timestamp":1710272454272,"user":{"displayName":"Amy Rouillard","userId":"08070373675321350328"},"user_tz":-120},"id":"GO0j-DoOXPFE"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","import pandas as pd\n","import os\n","import numpy as np\n","\n","# import CustomDataset from CustomDataset.py from utils folder\n","from CustomDataset import CustomDataset"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":63,"status":"ok","timestamp":1710273676329,"user":{"displayName":"Amy Rouillard","userId":"08070373675321350328"},"user_tz":-120},"id":"Kpb71CHFXPFF"},"outputs":[],"source":["# Load (train or test) data from csv file\n","path = \"C:/Users/Amy/Desktop/Green_Git/eegClassification/sample_data/\"\n","# path = \"./data/\"\n","\n","data_type = \"spec\" # \"eeg_raw\" #\"eeg_spec\"  #\n","train = True\n","text = \"train\" if train else \"test\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = pd.read_csv(path + f\"{text}.csv\")"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":866,"status":"ok","timestamp":1710273680715,"user":{"displayName":"Amy Rouillard","userId":"08070373675321350328"},"user_tz":-120},"id":"l4u2VfPMXPFF"},"outputs":[],"source":["\n","data_dir = (\n","    f\"{text}_eegs/\"\n","    if \"eeg\" in data_type\n","    else f\"{text}_spectrograms/\"\n",")\n","data_dir = path + data_dir\n","\n","votes_cols = [\n","    \"seizure_vote\",\n","    \"lpd_vote\",\n","    \"gpd_vote\",\n","    \"lrda_vote\",\n","    \"grda_vote\",\n","    \"other_vote\",\n","]\n","label_cols = (\n","    [\"eeg_id\", \"label_id\", \"eeg_label_offset_seconds\"]\n","    if \"eeg\" in data_type\n","    else [\"spectrogram_id\", \"label_id\", \"spectrogram_label_offset_seconds\"]\n",")\n","offset = (\n","    [\"eeg_label_offset_seconds\"]\n","    if \"eeg\" in data_type\n","    else [\"spectrogram_label_offset_seconds\"]\n",")\n"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":50,"status":"ok","timestamp":1710273682297,"user":{"displayName":"Amy Rouillard","userId":"08070373675321350328"},"user_tz":-120},"id":"apNKGYXwXry1"},"outputs":[],"source":["files = os.listdir(data_dir)\n","df = df[\n","    df[\"eeg_id\" if \"eeg\" in data_type else \"spectrogram_id\"].isin(\n","        [int(f.split(\".\")[0]) for f in files]\n","    )\n","]"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":75830,"status":"ok","timestamp":1710273758079,"user":{"displayName":"Amy Rouillard","userId":"08070373675321350328"},"user_tz":-120},"id":"_kQCWvuVXqp3"},"outputs":[],"source":["# if info_cols not in df add it and set to zero\n","for col in offset:\n","    if col not in df.columns:\n","        df[col] = 0\n","# if df does not contain \"label_id\" add a unique label_id\n","if \"label_id\" not in df.columns:\n","    df[\"label_id\"] = range(len(df))\n","\n","info = {}\n","df_gr = df.groupby(label_cols)\n","for name, group in df_gr:\n","    # first row of group\n","    info[name] = {\"votes\": group[votes_cols].values[0] if train else None}\n"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":110,"status":"ok","timestamp":1710273758079,"user":{"displayName":"Amy Rouillard","userId":"08070373675321350328"},"user_tz":-120},"id":"xEth-R0MXPFG"},"outputs":[],"source":["dataset = CustomDataset(data_dir, data_type, info)\n","dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":115411,"status":"ok","timestamp":1710273873406,"user":{"displayName":"Amy Rouillard","userId":"08070373675321350328"},"user_tz":-120},"id":"q0STDsExXPFG","outputId":"27a59e3d-aec1-470d-b7db-de40ae6ad634"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([16, 299, 100, 4]) torch.Size([16]) torch.Size([16, 6])\n"]}],"source":["count = 0\n","for data, label, class_probs in dataloader:\n","    print(data.shape, label.shape, class_probs.shape)\n","    count += 1\n","    if count > 0:\n","        break"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kSJeERm8XPFH","outputId":"f92e3dfe-f5e4-4958-9804-717993424b9f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Std: 1.7311e+00 MinMax: 1.1312e+01\n","Std: 1.3828e+00 MinMax: 1.1130e+01\n","Std: 1.0994e+00 MinMax: 1.0624e+01\n","Std: 1.0933e+00 MinMax: 1.0371e+01\n"]}],"source":["# create a data scaler\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","import pickle\n","\n","count = 0\n","# use the partial function to create a scaler\n","standard_scaler = StandardScaler()\n","min_max_scaler = MinMaxScaler()\n","for data, _, _ in dataloader:\n","  try:\n","    scale = standard_scaler.scale_\n","    min = min_max_scaler.data_min_\n","    max = min_max_scaler.data_max_\n","  except:\n","    scale = None\n","  standard_scaler.partial_fit(data.reshape(data.shape[0],-1))\n","  min_max_scaler.partial_fit(data.reshape(data.shape[0],-1))\n","  scale_new = standard_scaler.scale_\n","  min_new = min_max_scaler.data_min_\n","  max_new = min_max_scaler.data_max_\n","  if scale is not None:\n","    change = np.abs(scale_new - scale)\n","    change_minmax = np.abs([min_new - min, max_new - max])\n","    print(f\"Std: {change.max():.4e} MinMax: {change_minmax.max():.4e}\")\n","  count +=1\n","\n","  if count%10 == 0:\n","    # with open(path +f'{data_type}_standard_scaler.pkl', 'wb') as f:\n","    #   pickle.dump(standard_scaler, f)\n","    # with open(path + f'{data_type}_min_max_scaler.pkl', 'wb') as f:\n","    #     pickle.dump(min_max_scaler, f)\n","    print(\"saved\", count)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}
